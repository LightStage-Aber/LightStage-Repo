

LightStage_IlluminationOfTargetObject v0.1.2 -- 2016/03/08
----------------------------------------------------------
== PREREQUISITES
------------------
    Python2.7.x (5)
    PyOpenGL
    numpy
    
    To install PyOpenGL on Windows:
        First download:         PyOpenGL version '3.1.1b1-cp27' as x64 or x86 from http://www.lfd.uci.edu/~gohlke/pythonlibs/#pyopengl
        Then install as:        pip install path/to/download/PyOpenGL-3.1.1b1-cp27-none-win_XXXXX.whl

    To install PyOpenGL on Linux (Ubuntu/ Debian):
        sudo apt-get install python2.7 python-opengl numpy

    Note the 'pip' and 'easy_install' Python packages for PyOpenGL are incompatible with this project code, as tested on Windows 7 and Ubuntu 14.04 (2016/03/08).
    
    
== FILES:
-----------
    /src                                    - Code.
    /models                                 - Sample 3D obj model files.
    /blinn-phong+lambert_shading_scores     - Example scoring result data files.
    
    
== USAGE EXAMPLES:
-------------------
    python run.py -h
        Displays options on command line.

    python run.py
        Run in display mode (-m), with default mini-dome, default camera layout (-c) and default required LEDs (-l).

    python run.py -s 2 -t '(1,0,0)' -c 2
        Run in display mode, with a mini-dome scaled (-s) by 2, moved to position '1' on X-axis, with camera layout (-c) as 'even bias'.

    python run.py -p "../models/dome_c.obj" -s 2 -t '(0,0,0)' -l 41 -r ../results/blinn-phong+lambert_shading_scores/dome_realistic_cam/led_scores_2016-01-08-21-16-06.csv
        Run in display mode, with the dome from its obj file (-p), scaled (-s) by 2, not moved (-t), with 41 leds (-l) selected.
        Loads result data file (-r) for the dome model: ../blinn-phong+lambert_shading_scores/dome_realistic_cam/led_scores_2016-01-08-21-16-06.csv

    python run.py -p "../models/Flower/plants3.obj" -s 0.01 -t '(0,-4,0)' -r ../results/blinn-phong+lambert_shading_scores/plant3_realistic_cam/led_scores_2016-01-11-01-22-23.csv
        Run in display mode, with plants3.obj target model loaded (-p), with a scaling factor (-s) of 0.01 and translated (-t) -4 on the Y-axis
        Loads result data file (-r) for the plant3 model: ../results/blinn-phong+lambert_shading_scores/plant3_realistic_cam/led_scores_2016-01-11-01-22-23.csv

    python run.py -m 2 
        Run in evaluation mode (-m), with default mini-dome, default camera layout (-c) and default required LEDs (-l).
        This took 75 seconds, during testing.
        Created information file: ../led_meta_data_YYYY-MM-DD-hh-mm-ss.txt
        Created result data file: ../led_scores_YYYY-MM-DD-hh-mm-ss.csv

    python run.py -m 2 -p "../models/Flower/plants3.obj" -s 0.01 -t '(0,-4,0)'
        Run in evaluation mode (-m), with plants3.obj target model loaded (-p), with a scaling factor (-s) of 0.01 and translated (-t) -4 on the Y-axis.
        This took 83 minutes to run. Default is 'realistic bias' camera layout (-c), with 42 LEDs required (-l).
        Created information file: ../led_meta_data_YYYY-MM-DD-hh-mm-ss.txt
        Created result data file: ../led_scores_YYYY-MM-DD-hh-mm-ss.csv
    

== WHAT ARE THE KEYBOARD/MOUSE CONTROLS?:
------------------------------------------

    Press F1, see the console print outs.
    Use 'mouse' to drag and zoom view of object.
    Use 'space' to stop/start display rotation.
    

== WHAT DOES THIS PROGRAM DO?:
------------------------------

    (1) EVALUATES the illumination of a simulated object inside a LightStageV3.
    (2) DISPLAYS the resulting configuration(s) of LEDs that produce the best illumination of that object. 
    - These evaluations are based on two metrics that use the Lambertian diffuse and Blinn-Phong specular reflectance models.



== WHAT ARE THE PROGRAM MODES?:
------------------------------
    
    == DISPLAY MODE (Default):
        - Command line option (-m 1).
        - By default, we load a mini-dome and LED positions from a result data file '../led_scores.csv'.
        - In Display Mode, press F1 to view the runtime config options, such as key/mouse controls.
            - 'l' to load a new result data file.
            - 'r' to change between the data file's LED scoring measures.
                - (1) ranked maximised intensity. LEDs are selected during Display Mode runtime, based on rank. 
                      Use +/- to change the quantity of ranked LEDs displayed.
                - (2) minimised coverage error, default of 42 LEDs is set. 
                      LEDs displayed under this scoring have been selected during the Evaluation Mode run.
    
    == EVALUATION MODE:
        - Command line option (-m 2).
        - This mode will evaluate and log results to file evaluating ray reflection intensities into the observing cameras.
        - For a simple target model with 180 triangle it took 1.5 minutes to evaluate.
        - The result data file and meta data files are stored in '../led_scores_<timestamp>.csv' and '../led_meta_data_<timestamp>.txt' 
        - The evalution depends on:
            - camera positions
            - 6 rotations of the target model within the LightStage.
            - LED and quantity of LEDs desired
            - target model, positioning (scale and translation inside dome)
        - *We recommended that the camera layout and model positioning be set and previewed in the Display Mode before running in Evaluation Mode.*
        - The evaluation measures:
            - the light intensity score measure, uses Lambertian and Blinn-Phong reflection models to accumulate diffuse and specular 
              reflection intensities per tri, per LED.
            - the coverage error scoring measure, minimises the quantity of unlit target model triangle surfaces. This is done by 
              prioritising LEDs that are alone in lighting a tri surface, followed by prioritising LEDs that have a high 
              AccumIntensity * QtyTriHit score. With a limited search step and search depth, the best scoring set of LEDs are recorded, 
              of quantity (-l). 
              + AccumIntensity is the reflection intensity score per LED per tri of the target model, accumulated over the quantity of target model rotations.
              + QtyTriHit is the quantity of tris of the target model that are lit by the LED, accumulated over the quantity of target model rotations.
            
            

== USAGE OPTIONS:
-------------------        
    Usage: run.py [options]
    
    Options:
      -h, --help            show this help message and exit
      -m NUM, --mode=NUM    Specify the tool mode. 1=Display mode (default).
                            2=Evaluation mode.
      -e NUM, --evaluation-metric-mode=NUM
                            Specify the evaluation metric mode.'-e1' =Use
                            Reflectance Measures (default).
                            <NOT IMPLEMENTED> '-e2' =Use Illuminance
                            Measure Search (Lambertian only). '-e3' =Use
                            Illuminance Measure (Lambertian only); depends on
                            loaded result file (-r) read from column index 3 with
                            binary value 1.</NOT IMPLEMENTED>
      -p PATH, --target-path=PATH
                            Specify the path to an .obj file of the target model.
                            For example: '../dome_c.obj'. Default is a mini-dome.
      -s SCALE, --target-scale=SCALE
                            Specify the target model scaling factor. - Default=1.0
      -t (x,y,z), --target-translation=(x,y,z)
                            Specify the target model translation. i.e. move -1 on
                            Y-axis: '(0,-1,0)'
      -c NUM, --camera-layout=NUM
                            Specify the camera layout. 1=Realistic bias (default).
                            2=Even bias.
      -l NUM, --qty-leds=NUM
                            Specify the number of LEDs to show in demo and to
                            evaluate in range(0-92). Default is 44. *Note: This
                            value is not currently recalled from any results
                            files.*
      -r PATH, --load-result-file=PATH
                            Specify the path to an LED score result data file. For
                            example: '../led_scores_xxx.csv'.
      -k NUM, --reflectance-score=NUM
                            Specify the reflectance model scorings used in
                            evaluation mode. 1=Lambert's diffuse only. 2=Lambert's
                            diffuse and Blinn-Phong's specular (default).
      -d NUM, --display-evaluation-metric=NUM
                            Specify the evaluation metric display mode from result
                            file. 1=Use Index Column 1 Scores (default). 2=Use
                            Index Column 3 Scores (Lambertian only).

    
    
    
-----------------------------------------------------------------------------------------------------------------------------------------------
LightStage_LightPositioning_EvaluationTool v0.1.4 -- 2017/02/03
- Renamed.
- Refactored code after new luminance metrics and search method implementations were trialed. These new method implementations are not made available in this release.
- Coming up next: evaluate a loaded set of vertices. Map loaded set of vertices to possible frame mounting positions.
    
    
    
-----------------------------------------------------------------------------------------------------------------------------------------------
LightStage_IlluminationOfTargetObject v0.1.3 -- 2016/04/15
- Add Lambertian illumination (incidence) scores.
	- With a lambertian-like illuminance approach.
    - Use a fragment shader scoring approach to measure the illumination. Use lambertian score (~cosine of incidence) score at each surface.
    - Defaults to lambertian evaluations. See command line option (-k).
    
    

-----------------------------------------------------------------------------------------------------------------------------------------------
LightStage_IlluminationOfTargetObject v0.1.2 -- 2016/03/08
- Added Lambertian only reflectance scoring to evaluation mode. 
	- Added -k command line option to use this. 
- Included new result file for dome object model evaluation using Lambertian reflectance only.



-----------------------------------------------------------------------------------------------------------------------------------------------
LightProjection_on_Object v0.0.2 -- 2015/10/17
- Translated 'dome_c.obj' blender dome object into python functions to get dome vertices and edges/ faces. These vertices will be the LED light source vertices.
        @see dome_obj_data.py
- Calculated and drew lines to represent angles of incidence (from LED vertices) to a sample triangle face. This required functions to calculate the normalised perpendicular vector, the surface normal.
- Added a console printed boolean quantity measure of illumination. 1, if the projected LED angle of incidence is against the front face of the surface, else 0.
- Added 1 camera for future measure considering reflection angle into the camera.



LightProjection_on_Object v0.0.1 -- 2015/10/08
- Adapted a sample Py-OpenGL tutorial script to handle display loop, scene lighting and viewport manipulation via keyboard inputs, etc. 
        @see show_sample_reflection_opengl.py
- The handler module calls another module to manage drawing of specific objects in the scene and the model calculations. 
        @see draw_calc_lighting.py


To start with we'll use python 2.7 and opengl.
        sudo apt-get install python2.7 python-opengl numpy

