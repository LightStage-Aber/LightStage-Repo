

LightStage_LightPositioning_EvaluationTool
------------------------------------------

== PREREQUISITES
------------------
    Python2.7.x (5)
    PyOpenGL
    numpy
    
    To install PyOpenGL on Windows:
        First download:         PyOpenGL version '3.1.1b1-cp27' as x64 or x86 from http://www.lfd.uci.edu/~gohlke/pythonlibs/#pyopengl
        Then install as:        pip install path/to/download/PyOpenGL-3.1.1b1-cp27-none-win_XXXXX.whl

    To install PyOpenGL on Linux (Ubuntu/ Debian):
        sudo apt-get install python2.7 python-opengl numpy

    Note the 'pip' and 'easy_install' Python packages for PyOpenGL are incompatible with this project code, as tested on Windows 7 and Ubuntu 14.04 (2016/03/08).
    
    
== FILES:
-----------
    /src                                    - Code.
    /models                                 - Sample 3D obj model files.
    /results                                - Example scoring result data files.
    /properties								- Configuration file to simplify running of experiments; in particular with command line options: -e3 through to -e9.
    
    
== USAGE EXAMPLES:
-------------------
    python run.py -h
        Displays options on command line.

    python run.py
        Run in display mode (-m), with default mini-dome, default camera layout (-c) and default required LEDs (-l).

    python run.py -s 2 -t '(1,0,0)' -c 2
        Run in display mode, with a mini-dome scaled (-s) by 2, moved to position '1' on X-axis, with camera layout (-c) as 'even bias'.

    python run.py -p "../models/dome/dome_c.obj" -s 2 -t '(0,0,0)' -l 41 -r ../results/blinn-phong+lambert_shading_scores/dome_realistic_cam/led_scores_2016-01-08-21-16-06.csv
        Run in display mode, with the dome from its obj file (-p), scaled (-s) by 2, not moved (-t), with 41 leds (-l) selected.
        Loads result data file (-r) for the dome model: ../blinn-phong+lambert_shading_scores/dome_realistic_cam/led_scores_2016-01-08-21-16-06.csv

    python run.py -p "../models/Flower/plants3.obj" -s 0.01 -t '(0,-4,0)' -r ../results/blinn-phong+lambert_shading_scores/plant3_realistic_cam/led_scores_2016-01-11-01-22-23.csv
        Run in display mode, with plants3.obj target model loaded (-p), with a scaling factor (-s) of 0.01 and translated (-t) -4 on the Y-axis
        Loads result data file (-r) for the plant3 model: ../results/blinn-phong+lambert_shading_scores/plant3_realistic_cam/led_scores_2016-01-11-01-22-23.csv

    python run.py -m 2 
        Run in evaluation mode (-m), with default mini-dome, default camera layout (-c) and default required LEDs (-l).
        This took 75 seconds, during testing.
        Created information file: ../led_meta_data_YYYY-MM-DD-hh-mm-ss.txt
        Created result data file: ../led_scores_YYYY-MM-DD-hh-mm-ss.csv

    python run.py -m 2 -p "../models/Flower/plants3.obj" -s 0.01 -t '(0,-4,0)'
        Run in evaluation mode (-m), with plants3.obj target model loaded (-p), with a scaling factor (-s) of 0.01 and translated (-t) -4 on the Y-axis.
        This took 83 minutes to run. Default is 'realistic bias' camera layout (-c), with 42 LEDs required (-l).
        Created information file: ../led_meta_data_YYYY-MM-DD-hh-mm-ss.txt
        Created result data file: ../led_scores_YYYY-MM-DD-hh-mm-ss.csv
    

== WHAT ARE THE KEYBOARD/MOUSE CONTROLS?:
------------------------------------------

    Press F1, see the console print outs.
    Use 'mouse' to drag and zoom view of object.
    Use 'space' to stop/start display rotation.
    

== WHAT DOES THIS PROGRAM DO?:
------------------------------

    (1) EVALUATES the illumination of a simulated object inside a LightStageV3.
    (2) DISPLAYS the resulting configuration(s) of LEDs that produce the best illumination of that object. 
    - These evaluations are based on two metrics that use the Lambertian diffuse and Blinn-Phong specular reflectance models.



== WHAT ARE THE PROGRAM MODES?:
------------------------------
    
    == DISPLAY MODE (Default):
        - Command line option (-m 1).
        - By default, we load a mini-dome and LED positions from a result data file '../led_scores.csv'.
        - In Display Mode, press F1 to view the runtime config options, such as key/mouse controls.
            - 'l' to load a new result data file.
            - 'r' to change between the data file's LED scoring measures.
                - (1) ranked maximised intensity. LEDs are selected during Display Mode runtime, based on rank. 
                      Use +/- to change the quantity of ranked LEDs displayed.
                - (2) minimised coverage error, default of 42 LEDs is set. 
                      LEDs displayed under this scoring have been selected during the Evaluation Mode run.
    
    == EVALUATION MODE:
        - Command line option (-m 2).
        - This mode will execute evaluations of the given experiment (-e) type. 
        - To visually see what will be evaluated, use both the -m1 and -eX command line options. Then to evaluate that (recreated) scene, use -m2 -eX.
        - Option: (-m2 -e3 or 4)
        	- Evaluate the lambertian diffuse illuminance score of a set of index points read from an .csv results file and mapped to the internal dome's vertices by index, configuration set in /properties/default.properties.
		- Option: (-m2 -e7,8 or 9)
        	- Evaluate the lambertian diffuse illuminance score of a set of vertex points read from an .obj file, configuration set in /properties/default.properties.
        	- For evaluation of the raw vertex points loaded from the .obj file, use -e7.
        	- For mappings to the dome's closest (Euclidean dist) vertex point, use -e8.
        	- For mappings to the dome's closest (Euclidean dist) edge (of approx 10 points per edge), use -e9.
        	- Each will write out CSV results (including surface illuminations) to a csv file in a directory specified in default.properties.
        - Option: (-m2 -e2)
		    - This mode will evaluate and log results to file evaluating ray reflection intensities into the observing cameras.
		    - For a simple target model with 180 triangle it took 1.5 minutes to evaluate.
		    - The result data file and meta data files are stored in '../led_scores_<timestamp>.csv' and '../led_meta_data_<timestamp>.txt' 
		    - The evalution depends on:
		        - camera positions
		        - 6 rotations of the target model within the LightStage.
		        - LED and quantity of LEDs desired
		        - target model, positioning (scale and translation inside dome)
		    - *We recommended that the camera layout and model positioning be set and previewed in the Display Mode before running in Evaluation Mode.*
		    - The evaluation measures:
		        - the light intensity score measure, uses Lambertian and Blinn-Phong reflection models to accumulate diffuse and specular 
		          reflection intensities per tri, per LED.
		        - the coverage error scoring measure, minimises the quantity of unlit target model triangle surfaces. This is done by 
		          prioritising LEDs that are alone in lighting a tri surface, followed by prioritising LEDs that have a high 
		          AccumIntensity * QtyTriHit score. With a limited search step and search depth, the best scoring set of LEDs are recorded, 
		          of quantity (-l). 
		          + AccumIntensity is the reflection intensity score per LED per tri of the target model, accumulated over the quantity of target model rotations.
		          + QtyTriHit is the quantity of tris of the target model that are lit by the LED, accumulated over the quantity of target model rotations.

    == TUNING EVALUATION MODE:
        - Command line option (-m 3).
            - An extension of (-m2) evaluation mode.
            - This mode will tune (search for the best) LED position intensities values.
            - Always use together with (-e), the given experiment type.
        - Execute a search algorithm to "tune" (update) the intensity values, such that the normalised standard deviation measure improves.
            - To visually see the scene and which light positions will be evaluated, use both the -m1 and -eX command line options.
            - Run the intensity tuning search on a (recreated) scene, use -m3 -eX.
            - Note, that the (-m2) evaluation step will produce the un-tuned intensities per LED position as (1,1,1,1,1,1, etc.).
        - Choose the Search Algorithm and its parameters:
            - See ./properties/default.properties file, under the [Tune] section:
            - Option: "tune.mode=1"
                - Execute a search using scipy.optimize.basinhopping.
                - Method = L-BFGS-B, Intensity bounds are between 1.0 and 2.0 for all intensities.
            - Option: "tune.mode=2"
                - Execute an iterative regression, targetting the intensities with greatest surface z-scores.
                - tune.regression.threshold=0.005 [Range: >=0]
                - tune.regression.max_iterations=100 [Range: >=1]
            - Other search algorithms options may be added later.
        - Option: (-m3 -e3)
             - Untested.
        - Option: (-m3 -e7)
             - Untested.
        - Option: (-m3 -e8 or 9)
             - Map the equally distributed positions (as -m1 or -m2 -e8/9).
        - Option: (-m3 -e2)
             - Untested.

$ python run.py -h
Usage: run.py [options]

Options:
  -h, --help            show this help message and exit
  -m NUM, --mode=NUM    Specify the tool mode.
                        1=Display mode (default).
                        2=Evaluation mode.
                        3=Tune-evaluation mode.
  -e NUM, --evaluation-metric-mode=NUM
                        Specify the evaluation metric mode.
                        '-e0' =Default. (-m1) Display best selected LEDs from -e1 result file. (-m2) No action.
                        '-e1' =Use Reflectance Measures. 
                        '-e2' = (Disabled) Use Illuminance Measure Monte Carlo Search (Lambertian only). 
                        '-e3' =Use Illuminance Measure (Lambertian only) to evaluate 'Single' loaded
                        file; depends on properties file values: see '[EvaluateSingleResultsFile]' 
                        and '[FrameModel]' - (file, qty, column, etc.) in 'default.properties' file.
                        '-e4' =Use Illuminance Measure (Lambertian only) to evaluate 'Single Edge(10:3926)' loaded file;
                        depends on properties file values: see '[EvaluateEdgeMapSingleResultsFile]'
                        '-e7' =Use Illuminance Measure (Lambertian only) to evaluate 'RAW' vertex 
                        position file; depends on properties file values: see '[LightPositions]'
                        '-e8' =Use Illuminance Measure (Lambertian only) to evaluate 'Vertex
                        Mappings' vertex position file; depends on properties file values: see '[LightPositions]'
                        '-e9' =Use Illuminance Measure (Lambertian only) to evaluate
                        'Edge(10) Mappings' vertex position file; depends on properties file values: see '[LightPositions]'
  -p PATH, --target-path=PATH
                        Specify the path to an .obj file of the target model.
                        For example: '../models/dome/dome_c.obj'. Default is a mini-dome.
  -s SCALE, --target-scale=SCALE
                        Specify the target model scaling factor. - Default=1.0
  -t (x,y,z), --target-translation=(x,y,z)
                        Specify the target model translation. i.e. move -1 on
                        Y-axis: '(0,-1,0)'
  -c NUM, --camera-layout=NUM
                        Specify the camera layout. 1=Realistic bias (default).
                        2=Even bias.
  -l NUM, --qty-leds=NUM
                        Specify the number of LEDs to show in demo and to
                        evaluate in range(0-92). Default is 44. *Note: This
                        value is not currently recalled from any results
                        files.*
  -r PATH, --load-result-file=PATH
                        Specify the path to an LED score result data file. For
                        example: '../led_scores_xxx.csv'.
  -k NUM, --reflectance-score=NUM
                        Specify the reflectance model scorings used in
                        evaluation mode. 1=Lambert's diffuse only. 2=Lambert's
                        diffuse and Blinn-Phong's specular (default).
  -d NUM, --display-evaluation-metric=NUM
                        Specify the evaluation metric display mode from result
                        file. 1=Use Index Column 1 Scores (default). 2=Use
                        Index Column 3 Scores (Lambertian only).




Todo: Planned release: LightStage_LightPositioning_EvaluationTool v0.1.82 -- 2017/05/
Todo: - Integrate Saff97 spheres, via antiprism.
Todo: - Integrate Repulsion by percentage move, via antiprism.
Todo: - Create test suites for PLOS One paper including new Saff97 (as Geometric) and Repulsion by% with byJitter (as Repulsion).
Todo: - Create test suites for PLOS One paper with new target models (plant dataset, head/face dataset, sphere).

Todo: Planned release: - LightStage_LightPositioning_EvaluationTool v0.1.81 -- 2017/05/
Todo: - Create test suites for PLOS One paper for Tuning tests.
Todo: - Refactor - Move dependencies of "Old_ToolSelector" (i.e. luminance evaluation and viewing techniques) from input arguments (and as globals) to properties key-value pairs. Remove capability to set number of LEDs in both locations.


LightStage_LightPositioning_EvaluationTool v0.1.8 -- 2017/04/25
---------------------------------------------------------------
Major changes:
- Created test suites for PLOS One paper control experiments. Reevaluated Control and Monte Carlo experiment results.
- Speed up visualisation with cached loaded (from ~1 FPS to ~30FPS). Added ToolSelector cache class to improve performance / remove requirement of file I/O every frame, (from ~1fps to ~30fps). Further improvements with "modern" opengl implementation (i.e. single glBegin/End batch call).
- Bug fixed: bug in Edge-point determination/ definition; when support access is enabled, all edges connected to the removed support access vertex are ignored (not created).
- Bug fixed: ensured correct usage of "loaded OBJ dome model vs hard coded dome model" for target and frame.
Todo: - Add Tuning feature.
Todo: - Create test suite and reevaluate Repulsion (Lettvin Edge10Mappings).

Minor changes:
- Added 'frame.withsupportaccess' (bool) to default.properties file, loaded and used -e3,4,7,8,9.
- Refactorings and added unit tests.
- Open issue: The hardcoded dome model has one missing tri on the model, due to the face mappings. The vertex mappings (by AOS 06/2016) to the physical dome are accurate. The missing tri affects the Face-to-Edge algorithm (i.e. Edge10) and evaluations using it as a target model.


    
LightStage_LightPositioning_EvaluationTool v0.1.7 -- 2017/04/01
---------------------------------------------------------------
- Increased clipping distance ten fold to aid model loading and debugging.


LightStage_LightPositioning_EvaluationTool v0.1.6 -- 2017/03/29
-----------------------------------------------------------------------------------------------------------------------------------------------
- Added mapping of vertex positions loaded from .obj file to dome edges. Use with '-e9' command line option and configured using default.properties file.
- Minor changes for experimental testing and to documentation. Results not included in commit.


LightStage_LightPositioning_EvaluationTool v0.1.5 -- 2017/02/03
-----------------------------------------------------------------------------------------------------------------------------------------------
- Added loading explicit light (FrameModel) vertex positions from an .obj file, via the .ini format file at "../properties/default.properties".
- Evaluate those light positions with standard deviation of lambert diffuse reflectance (illuminance only) in class 'MeasureLoadedLightPositions' in illuminance.py.
- Map loaded light vertex positions (from file) to the closest frame joint positions (from "/data_3d/dome_obj_data.py").

    
-----------------------------------------------------------------------------------------------------------------------------------------------
LightStage_LightPositioning_EvaluationTool v0.1.4 -- 2017/02/03
- Renamed.
- Refactored code after new illuminance metrics and search method implementations were trialed. These new method implementations are not made available in this release.
- Note that the mappings in 'dome_obj_data.py' have been modified (by AOS) to match the actual dome vertex numberings.
- Coming up next: evaluate a loaded set of vertices. Map loaded set of vertices to possible frame mounting positions.
    
    
    
-----------------------------------------------------------------------------------------------------------------------------------------------
LightStage_IlluminationOfTargetObject v0.1.3 -- 2016/04/15
- Add Lambertian illumination (incidence) scores.
	- With a lambertian-like illuminance approach.
    - Use a fragment shader scoring approach to measure the illumination. Use lambertian score (~cosine of incidence) score at each surface.
    - Defaults to lambertian evaluations. See command line option (-k).
    
    

-----------------------------------------------------------------------------------------------------------------------------------------------
LightStage_IlluminationOfTargetObject v0.1.2 -- 2016/03/08
- Added Lambertian only reflectance scoring to evaluation mode. 
	- Added -k command line option to use this. 
- Included new result file for dome object model evaluation using Lambertian reflectance only.



-----------------------------------------------------------------------------------------------------------------------------------------------
LightProjection_on_Object v0.0.2 -- 2015/10/17
- Translated 'dome_c.obj' blender dome object into python functions to get dome vertices and edges/ faces. These vertices will be the LED light source vertices.
        @see dome_obj_data.py
- Calculated and drew lines to represent angles of incidence (from LED vertices) to a sample triangle face. This required functions to calculate the normalised perpendicular vector, the surface normal.
- Added a console printed boolean quantity measure of illumination. 1, if the projected LED angle of incidence is against the front face of the surface, else 0.
- Added 1 camera for future measure considering reflection angle into the camera.



LightProjection_on_Object v0.0.1 -- 2015/10/08
- Adapted a sample Py-OpenGL tutorial script to handle display loop, scene lighting and viewport manipulation via keyboard inputs, etc. 
        @see show_sample_reflection_opengl.py
- The handler module calls another module to manage drawing of specific objects in the scene and the model calculations. 
        @see draw_calc_lighting.py


To start with we'll use python 2.7 and opengl.
        sudo apt-get install python2.7 python-opengl numpy

